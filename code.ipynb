{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BDRAD.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awvZrWXWQZPD"
      },
      "source": [
        "# **Setup**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uV6MOKqIOQaQ",
        "outputId": "20d2e133-0b03-4916-d28b-fc4a8c305a4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install pydicom"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydicom in /usr/local/lib/python3.6/dist-packages (2.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQTtjXzwJh3S"
      },
      "source": [
        "import pydicom as pdm\n",
        "import skimage as sk\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "from skimage.transform import resize\n",
        "from skimage.io import imread\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PggBthhEJskr",
        "outputId": "8e7aade6-12bf-4e7e-e438-ef2c15427fa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "# drive.flush_and_unmount()\n",
        "os.chdir(\"/content/gdrive/My Drive/Colab Notebooks/data\")\n",
        "os.getcwd()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/gdrive/My Drive/Colab Notebooks/data'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mn7cUWVgQoFY"
      },
      "source": [
        "# **Part 1: Working with image files**\n",
        "*   Load DICOM or PNG file.\n",
        "*   Resize the image to user-specified dimensions (e.g. 229 x 229).\n",
        "*   Write the resized image to numpy .npy files.\n",
        "*   Combine the .npy files with breast density information. Store this into numpyz .npz files.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pCA9euFTlCe"
      },
      "source": [
        "def resize_image(filepath, custom_shape, verbose=False):\n",
        "  assert os.path.exists(filepath), \"ERROR: file \" + filepath + \" not found!\"\n",
        "\n",
        "  if filepath.endswith(\".png\"):\n",
        "    png_ndarray = imread(filepath)\n",
        "    print_msg(\"Resizing PNG file...\", verbose)\n",
        "    png_resized = resize(image=png_ndarray, output_shape=custom_shape, anti_aliasing=False)\n",
        "    print_msg(\"Success.\", verbose)\n",
        "    return (png_ndarray, png_resized)\n",
        "\n",
        "  else:\n",
        "    print_msg(\"Reading DICOM file...\", verbose)\n",
        "    dicom_dataset = pdm.dcmread(fp=filepath, defer_size=None, force=True)\n",
        "    if not filepath.endswith(\"dcm\"):\n",
        "      print_msg(\"Decompressing DICOM file...\", verbose)\n",
        "      dicom_dataset = dicom_dataset.decompress()\n",
        "    dicom_ndarray = dicom_dataset.pixel_array\n",
        "    print_msg(\"Success.\", verbose)\n",
        "\n",
        "    print_msg(\"Resizing DICOM file...\", verbose)\n",
        "    dicom_resized = resize(image=dicom_ndarray, output_shape=custom_shape, anti_aliasing=False)\n",
        "    print_msg(\"Success.\", verbose) \n",
        "\n",
        "    return (dicom_dataset, dicom_resized)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LIqShYpbMht"
      },
      "source": [
        "def save_to_npy(save_to, arr_data, verbose=False):\n",
        "  npy_path = save_to + \".npy\"\n",
        "  np.save(npy_path, arr_data)\n",
        "  print_msg(\"Success.\", verbose)\n",
        "\n",
        "  return npy_path"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztEx2YT3TsY1"
      },
      "source": [
        "def save_to_npz(save_to, read_from, breast_density, verbose=False):\n",
        "  print_msg(\"Loading npy file \" + read_from + \"...\", verbose)\n",
        "  resized_arr = np.load(file=read_from, allow_pickle=False)\n",
        "  num_rows, num_cols = resized_arr.shape\n",
        "  print_msg(\"Success.\", verbose)\n",
        "\n",
        "  print_msg(\"Creating new data with breast_density ...\", verbose)\n",
        "  new_arr = np.zeros((num_rows + 1, num_cols))\n",
        "  for i in range(num_rows):\n",
        "    new_arr[i] = resized_arr[i,:]\n",
        "  new_arr[num_rows] = np.full(shape=(num_cols,), fill_value=breast_density)\n",
        "  print_msg(\"Success.\", verbose)\n",
        "\n",
        "  npz_path = save_to + \".npz\"\n",
        "  print_msg(\"Saving to npz file \" + npz_path + \"...\", verbose)\n",
        "  np.savez(npz_path, new_arr)\n",
        "  print_msg(\"Success.\", verbose)\n",
        "\n",
        "  return npz_path"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDdYjDBAbZ25"
      },
      "source": [
        "def get_patient_id(filepath):\n",
        "  i = filepath.index(\"P_\") + 2\n",
        "  patient_id = \"P_\"\n",
        "  while filepath[i].isnumeric():\n",
        "    patient_id += filepath[i]\n",
        "    i += 1\n",
        "  print(\"patient id is \" + patient_id)\n",
        "  return patient_id"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFM8HND8bcPp"
      },
      "source": [
        "def get_breast_density(df, patient_id):\n",
        "  breast_density = df.loc[patient_id, \"breast_density\"]\n",
        "  if breast_density.size > 1:\n",
        "    breast_density = breast_density[0]\n",
        "  return breast_density"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eE_wkWibeRT"
      },
      "source": [
        "def get_image_files(dir_path):\n",
        "  print(\"getting image files...\")\n",
        "  train_files = {}\n",
        "  test_files = {}\n",
        "  for root, dirs, files in os.walk(dir_path):\n",
        "    if files and files[0].endswith(\".dcm\"):\n",
        "      if \"Training\" in root:\n",
        "        train_files[root] = files[0]\n",
        "      elif \"Testing\" in root:\n",
        "        test_files[root] = files[0]\n",
        "  print(\"done getting image files!\")\n",
        "  return (train_files, test_files)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpOSbRJwbg8f"
      },
      "source": [
        "def get_scan_type(filepath):\n",
        "  scan_type = \"LEFT_\" if \"LEFT_\" in filepath else \"RIGHT_\"\n",
        "  scan_type += \"CC\" if \"CC\" in filepath else \"MLO\"\n",
        "  return scan_type"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msNGCLJEb874"
      },
      "source": [
        "def print_msg(msg, verbose):\n",
        "  if verbose:\n",
        "    print(msg)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3d1OWj-5cGKg"
      },
      "source": [
        "def sort_npy_npz_files(dir):\n",
        "  npy_dir = os.path.join(dir, \"npy files\")\n",
        "  if not os.path.exists(npy_dir):\n",
        "    os.mkdir(npy_dir)\n",
        "  npz_dir = os.path.join(dir, \"npz files\")\n",
        "  if not os.path.exists(npz_dir):\n",
        "    os.mkdir(npz_dir)\n",
        "  for f in os.listdir(dir):\n",
        "    if f.endswith(\".npy\"):\n",
        "      os.rename(os.path.join(dir, f), os.path.join(dir, npy_dir, f))\n",
        "    elif f.endswith(\".npz\"):\n",
        "      os.rename(os.path.join(dir, f), os.path.join(dir, npz_dir, f))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xk8ENoqVbiaA"
      },
      "source": [
        "def main_helper(files_dict, df, resize_shape=(229, 229), save=True, verbose=False):\n",
        "  \n",
        "  data = []\n",
        "  labels = []\n",
        "  # resize_dir = os.path.join(os.getcwd(), \"resized images\")\n",
        "\n",
        "  for fpath in files_dict:\n",
        "    patient_id = get_patient_id(fpath)\n",
        "    scan_type = get_scan_type(fpath)\n",
        "    breast_density = get_breast_density(df, patient_id)\n",
        "    image_fp = files_dict[fpath]\n",
        "\n",
        "    dataset, resized_ndarray = resize_image(filepath=os.path.join(fpath, image_fp), custom_shape=resize_shape, verbose=verbose)\n",
        "    # if save:\n",
        "    #   if not os.path.exists(resize_dir):\n",
        "    #     os.mkdir(resize_dir)\n",
        "    #   output_path = os.path.join(resize_dir, patient_id + \"_\" + scan_type + \"_\" + image_fp)\n",
        "    #   print_msg(\"Saving resized image to \" + output_path, verbose)\n",
        "    #   if image_fp.endswith(\"PNG\"):\n",
        "    #     plt.imsave(output_path, resized_ndarray)\n",
        "    #   else:\n",
        "    #     # new_ds = pdm.dataset.Dataset(dataset)\n",
        "    #     dataset.save_as(output_path)\n",
        "    #   print_msg(\"Success.\", verbose)\n",
        "    np_path = os.path.join(os.getcwd(), patient_id + \"_\" + scan_type)\n",
        "    npy_path = save_to_npy(save_to=np_path, arr_data=resized_ndarray, verbose=verbose)\n",
        "    npz_path = save_to_npz(save_to=np_path, read_from=npy_path, breast_density=breast_density)\n",
        "    sort_npy_npz_files(os.getcwd())\n",
        "\n",
        "    data.append(resized_ndarray)\n",
        "    labels.append(0 if breast_density <= 2 else 1) # not dense for 1, 2 ; dense for 3, 4\n",
        "\n",
        "  return (data, labels)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbICoNezbkjg"
      },
      "source": [
        "def main(dir_path, resize_shape=(229, 229), save=True, verbose=False):\n",
        "  train_csv = os.path.join(os.getcwd(), \"mass_case_description_train_set.csv\")\n",
        "  test_csv = os.path.join(os.getcwd(), \"mass_case_description_test_set.csv\")\n",
        "  train_df = pd.read_csv(train_csv, index_col=\"patient_id\")\n",
        "  test_df = pd.read_csv(test_csv, index_col=\"patient_id\")\n",
        "\n",
        "  train_files, test_files = get_image_files(dir_path)\n",
        "\n",
        "  train_data, train_labels = main_helper(train_files, train_df, resize_shape, save, verbose)\n",
        "  test_data, test_labels = main_helper(test_files, test_df, resize_shape, save, verbose)\n",
        "  return (train_data, train_labels, test_data, test_labels)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zf65aFCubuEv"
      },
      "source": [
        "# **Testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1q8g9uEbA6AX"
      },
      "source": [
        "# pdm.config.debug()\n",
        "dir_path = os.getcwd()\n",
        "train_data, train_labels, test_data, test_labels = main(dir_path, verbose=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IhDh3UxcbX1"
      },
      "source": [
        "# **Part 2: Machine Learning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hcz1_CcpZCdm"
      },
      "source": [
        "train_data = np.asarray(train_data)\n",
        "train_data.shape # (250, 299, 299)\n",
        "train_data = tf.convert_to_tensor(train_data)\n",
        "print(train_data)\n",
        "\n",
        "train_labels = np.asarray(train_labels)\n",
        "train_labels.shape # (250,)\n",
        "\n",
        "# test_data = np.asarray(test_data)\n",
        "# test_data.shape # (250, 299, 299)\n",
        "\n",
        "# test_labels = np.asarray(test_labels)\n",
        "# test_labels.shape # (250,)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYLkMYA4skXm"
      },
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_data, train_labels))\n",
        "# train_dataset = tf.data.Dataset.from_tensor_slices((test_data, test_labels))"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBB_n07rtb4h"
      },
      "source": [
        "batch_size = 5\n",
        "shuffle_buffer_size = 50\n",
        "\n",
        "train_dataset = train_dataset.shuffle(shuffle_buffer_size).batch(batch_size)\n",
        "# test_dataset = test_dataset.batch(batch_size)\n",
        "for element in train_dataset.as_numpy_iterator():\n",
        "  print(element)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBV0ENIMt3ZH"
      },
      "source": [
        "###########################\n",
        "# Citation: from tensorflow.org\n",
        "steps_per_epoch = 250/batch_size\n",
        "\n",
        "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
        "                    0.001,\n",
        "                    decay_steps=steps_per_epoch*1000,\n",
        "                    decay_rate=1,\n",
        "                    staircase=False)\n",
        "\n",
        "def get_optimizer():\n",
        "  return tf.keras.optimizers.Adam(lr_schedule)\n",
        "\n",
        "step = np.linspace(0,100000)\n",
        "lr = lr_schedule(step)\n",
        "plt.figure(figsize = (8,6))\n",
        "plt.plot(step/steps_per_epoch, lr)\n",
        "plt.ylim([0,max(plt.ylim())])\n",
        "plt.xlabel('Epoch')\n",
        "_ = plt.ylabel('Learning Rate')\n",
        "###########################\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dense(128, activation='relu'),\n",
        "            tf.keras.layers.Dense(64, activation='tanh'),\n",
        "            tf.keras.layers.Dense(32, activation='sigmoid'),\n",
        "            tf.keras.layers.Dense(2)\n",
        "])\n",
        "\n",
        "model.compile(optimizer=get_optimizer(),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['sparse_categorical_accuracy'])\n",
        "\n",
        "model.fit(train_dataset, epochs=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaR7YwnBLyLn"
      },
      "source": [
        "\n",
        "# **Documentation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMcPgwlERiMO"
      },
      "source": [
        "**`resize_image(filepath, custom_shape, show=True, verbose=False)`**\n",
        "*   Inputs \n",
        "  * FILEPATH: string path of image file to resize\n",
        "  * CUSTOM_SHAPE: tuple of resized dimensions (e.g. (299, 299))\n",
        "  * [SHOW=True]: plot image before and after resizing\n",
        "  * [VERBOSE=False]: do not print intermediate progress\n",
        "*   Outputs\n",
        "  1. if DICOM, dataframe; if PNG, original image numpy array\n",
        "  2. resized array\n",
        "*  Functionality\n",
        "  * Resizes input image file to custom dimension and returns the original dataframe or image array and the resized array. \n",
        "\n",
        "\n",
        "**`save_to_npy(filepath, arr_data, verbose=False)`**\n",
        "*   Inputs\n",
        "  * FILEPATH: desired numpy filepath string (no extensions)\n",
        "  * ARR_DATA: numpy array to save in the numpy file\n",
        "  * [VERBOSE=False]: do not print intermediate progress\n",
        "*   Outputs\n",
        "  1. NPY_PATH: the full numpy filepath (with .npy extension)\n",
        "*   Functionality\n",
        "  * Saves input data to a numpy file using the desired filepath.\n",
        "\n",
        "\n",
        "**`save_to_npz(save_to, read_from, breast_density, verbose=False)`**\n",
        "*   Inputs\n",
        "  * SAVE_TO: desired numpyz filepath string (no extensions)\n",
        "  * READ_FROM: numpy filepath containing the resized image ndarray\n",
        "  * BREAST_DENSITY: integer\n",
        "  * [VERBOSE=False]: do not print intermediate progress\n",
        "*   Outputs\n",
        "    1. NPZ_PATH: the full numpyz path (with .npz extension)\n",
        "*   Functionality\n",
        "  * Saves input array and breast density to a new numpyz file.\n",
        "\n",
        "**`get_breast_density(df, patient_id)`**\n",
        "*  Inputs\n",
        "  * DF: dataframe from reading csv file (for breast density info)\n",
        "  * PATIENT_ID: patient id (attribute of dataset from reading DICOM file)\n",
        "*  Outputs\n",
        "    1. breast density (integer) of input patient\n",
        "*  Functionality\n",
        "  * Returns the breast density corresponding to PATIENT_ID\n",
        "\n",
        "\n",
        "**`main`**\n",
        "*  Inputs\n",
        "  * DIR: directory of image files to operate on\n",
        "  * [RESIZE_SHAPE=(229, 229)]: tuple of desired resizing dimensions\n",
        "  * [VERBOSE=False]: do not print intermediate progress\n",
        "*  Outputs\n",
        "  * 1. python array of training image pixel arrays\n",
        "  * 2. python array of training labels (*i*th label corresponds to the *i*th training image pixel array)\n",
        "  * 3. python array of testing image pixel arrays\n",
        "  * 4. python array of testing labels (*i*th label corresponds to the *i*th training image pixel array)\n",
        "*  Functionality\n",
        "  * For each DICOM file in DIR,\n",
        "    1. resize\n",
        "    2. save to numpy file\n",
        "    3. save to numpyz file with breast density information"
      ]
    }
  ]
}